spring:
  application:
    name: li-ai-code-ai
server:
  port: 8125
# AI
langchain4j:
  open-ai:
    chat-model:
      base-url: https://api.deepseek.com
      api-key: ${langchain4j.open-ai.chat-model.api-key}
      model-name: deepseek-chat
      log-requests: true
      log-responses: true
    #      strict-json-schema: true
    #      response-format: json_object
    streaming-chat-model:
      base-url: https://api.deepseek.com
      api-key: ${langchain4j.open-ai.chat-model.api-key}
      model-name: deepseek-chat
      max-tokens: 8192
      log-requests: true
      log-responses: true
    reasoning-streaming-chat-model:
      base-url: https://api.deepseek.com
      api-key: ${langchain4j.open-ai.chat-model.api-key}
      model-name: deepseek-chat
      max-tokens: 8192
      temperature: 0.1
      log-requests: true
      log-responses: true
    routing-chat-model:
      base-url: https://api.deepseek.com
      api-key: ${langchain4j.open-ai.chat-model.api-key}
      model-name: deepseek-chat
      log-requests: true
      log-responses: true
